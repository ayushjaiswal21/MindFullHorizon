{% extends "base.html" %}

{% block title %}Voice Logs - Mindful Horizon{% endblock %}

{% block content %}
<div class="patient-voice-logs-container">
    <div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-8">
        <!-- Header -->
        <div class="mb-8">
            <div class="flex items-center justify-between">
                <div>
                    <h1 class="text-3xl font-bold text-gray-900 mb-2">Voice Logs</h1>
                    <p class="text-gray-600">Record and analyze your voice for emotional insights</p>
                </div>
                <a href="{{ url_for('patient.patient_dashboard') }}" class="btn-secondary">
                    <i class="fas fa-arrow-left mr-2"></i>Back to Dashboard
                </a>
            </div>
        </div>

        <!-- Voice Recording Section -->
        <div class="patient-card p-6 mb-8">
            <h2 class="text-xl font-semibold text-gray-800 mb-4">
                <i class="fas fa-microphone text-green-500 mr-2"></i>Voice Recording
            </h2>

            <!-- Recording Interface -->
            <div class="bg-gray-50 rounded-lg p-6 mb-4">
                <div class="text-center mb-4">
                    <button id="recordBtn" onclick="startRecording()" class="btn-primary mr-4">
                        <i class="fas fa-circle mr-2"></i>Start Recording
                    </button>
                    <button id="stopBtn" onclick="stopRecording()" disabled class="btn-secondary mr-4">
                        <i class="fas fa-stop mr-2"></i>Stop Recording
                    </button>
                    <button id="uploadBtn" onclick="uploadRecording()" disabled class="btn-success">
                        <i class="fas fa-upload mr-2"></i>Upload & Analyze
                    </button>
                </div>

                <div class="text-center">
                    <div id="recordingStatus" class="text-sm text-gray-600 mb-2">Ready to record</div>
                    <div id="timer" class="text-lg font-mono text-gray-800">00:00</div>
                </div>

                <!-- Audio Visualization -->
                <div class="mt-4 flex justify-center">
                    <canvas id="waveform" width="400" height="60" class="border border-gray-300 rounded"></canvas>
                </div>
            </div>

            <!-- Recording Guidelines -->
            <div class="bg-blue-50 border border-blue-200 rounded-lg p-4">
                <h3 class="font-medium text-blue-900 mb-2">Recording Guidelines:</h3>
                <ul class="text-sm text-blue-800 space-y-1">
                    <li>‚Ä¢ Speak clearly for 30 seconds to 2 minutes</li>
                    <li>‚Ä¢ Find a quiet environment</li>
                    <li>‚Ä¢ Express how you're feeling naturally</li>
                    <li>‚Ä¢ Maximum recording time: 2 minutes</li>
                </ul>
            </div>
        </div>

        <!-- Upload Status -->
        <div id="uploadStatus" class="patient-card p-6 mb-8 hidden">
            <h2 class="text-xl font-semibold text-gray-800 mb-4">
                <i class="fas fa-spinner fa-spin mr-2"></i>Processing Voice Log
            </h2>
            <p class="text-gray-600">Analyzing your voice recording...</p>
        </div>

        <!-- Voice Logs List -->
        <div class="patient-card p-6">
            <h2 class="text-xl font-semibold text-gray-800 mb-4">
                <i class="fas fa-list text-orange-500 mr-2"></i>Your Voice Logs
            </h2>

            {% if voice_logs %}
                <div class="space-y-4">
                    {% for log in voice_logs|reverse %}
                    <div class="border border-gray-200 rounded-lg p-4 hover:shadow-md transition-shadow" data-log-id="{{ log.id }}">
                        <div class="flex items-center justify-between mb-3">
                            <div class="flex items-center space-x-3">
                                <i class="fas fa-microphone text-gray-400"></i>
                                <div>
                                    <h3 class="text-lg font-semibold text-gray-900">
                                        Voice Log #{{ loop.index }}
                                    </h3>
                                    <p class="text-sm text-gray-500">
                                        {{ log.created_at.strftime('%B %d, %Y at %I:%M %p') }}
                                    </p>
                                </div>
                            </div>
                            <div class="flex items-center space-x-2">
                                {% if log.ai_analysis %}
                                    {% set emotion = log.ai_analysis.split(':')[0].lower() %}
                                    <span class="px-3 py-1 text-sm font-medium rounded-full {% if emotion == 'happy' %}bg-green-100 text-green-800{% elif emotion == 'sad' %}bg-blue-100 text-blue-800{% elif emotion == 'stressed' %}bg-red-100 text-red-800{% elif emotion == 'angry' %}bg-orange-100 text-orange-800{% elif emotion == 'calm' %}bg-purple-100 text-purple-800{% elif emotion == 'excited' %}bg-yellow-100 text-yellow-800{% else %}bg-gray-100 text-gray-800{% endif %}">
                                        {% if emotion == 'happy' %}üòä
                                        {% elif emotion == 'sad' %}üò¢
                                        {% elif emotion == 'stressed' %}üò∞
                                        {% elif emotion == 'angry' %}üò†
                                        {% elif emotion == 'calm' %}üòå
                                        {% elif emotion == 'excited' %}ü§©
                                        {% else %}üòê
                                        {% endif %}
                                        {{ emotion|title }}
                                    </span>
                                {% else %}
                                    <span class="px-3 py-1 text-sm font-medium rounded-full {% if log.emotion == 'happy' %}bg-green-100 text-green-800{% elif log.emotion == 'sad' %}bg-blue-100 text-blue-800{% elif log.emotion == 'stressed' %}bg-red-100 text-red-800{% else %}bg-gray-100 text-gray-800{% endif %}">
                                        {% if log.emotion == 'happy' %}üòä
                                        {% elif log.emotion == 'sad' %}üò¢
                                        {% elif log.emotion == 'stressed' %}üò∞
                                        {% else %}üòê
                                        {% endif %}
                                        {{ log.emotion|title }}
                                    </span>
                                {% endif %}
                            </div>
                        </div>

                        <!-- Audio Features -->
                        {% if log.audio_features %}
                        <div class="mb-3">
                            <h4 class="text-sm font-medium text-gray-700 mb-2">Audio Analysis:</h4>
                            <div class="grid grid-cols-2 md:grid-cols-4 gap-2 text-xs">
                                <div class="bg-gray-50 p-2 rounded">
                                    <span class="font-medium">Duration:</span>
                                    <span class="text-gray-600">{{ "%.1f"|format(log.audio_features.duration or 0) }}s</span>
                                </div>
                                {% if log.audio_features.mean_pitch %}
                                <div class="bg-gray-50 p-2 rounded">
                                    <span class="font-medium">Pitch:</span>
                                    <span class="text-gray-600">{{ "%.0f"|format(log.audio_features.mean_pitch) }} Hz</span>
                                </div>
                                {% endif %}
                                {% if log.audio_features.mean_energy %}
                                <div class="bg-gray-50 p-2 rounded">
                                    <span class="font-medium">Energy:</span>
                                    <span class="text-gray-600">{{ "%.3f"|format(log.audio_features.mean_energy) }}</span>
                                </div>
                                {% endif %}
                                {% if log.audio_features.mean_zcr %}
                                <div class="bg-gray-50 p-2 rounded">
                                    <span class="font-medium">Voice Quality:</span>
                                    <span class="text-gray-600">{{ "%.3f"|format(log.audio_features.mean_zcr) }}</span>
                                </div>
                                {% endif %}
                            </div>
                        </div>
                        {% endif %}

                        <!-- AI Analysis -->
                        {% if log.ai_analysis %}
                        <div class="mt-4 p-3 bg-blue-50 border border-blue-200 rounded-lg">
                            <h4 class="text-sm font-medium text-blue-900 mb-2">
                                <i class="fas fa-robot text-blue-600 mr-1"></i>AI Emotion Analysis
                            </h4>
                            <p class="text-sm text-blue-800">{{ log.ai_analysis }}</p>
                        </div>
                        {% endif %}

                        <!-- Audio Player -->
                        <div class="flex items-center space-x-4">
                        <audio controls class="flex-1">
                            <source src="{{ url_for('static', filename='uploads/' + log.filename) }}" type="audio/wav">
                            <source src="{{ url_for('static', filename='uploads/' + log.filename) }}" type="audio/mpeg">
                            Your browser does not support the audio element.
                        </audio>
                            <button onclick="deleteVoiceLog('{{ log.id }}')" class="text-red-500 hover:text-red-700">
                                <i class="fas fa-trash"></i>
                            </button>
                        </div>
                    </div>
                    {% endfor %}
                </div>
            {% else %}
                <div class="text-center py-8">
                    <i class="fas fa-microphone-slash text-4xl text-gray-300 mb-4"></i>
                    <p class="text-gray-500">No voice logs yet. Start recording to analyze your emotional state!</p>
                </div>
            {% endif %}
        </div>
    </div>
</div>

<script>
let mediaRecorder;
let audioChunks = [];
let recordingTimer;
let startTime;

function startRecording() {
    navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
            mediaRecorder = new MediaRecorder(stream);
            audioChunks = [];

            mediaRecorder.ondataavailable = event => {
                audioChunks.push(event.data);
            };

            mediaRecorder.onstop = () => {
                stream.getTracks().forEach(track => track.stop());
            };

            mediaRecorder.start();
            startTime = Date.now();

            // Update UI
            document.getElementById('recordBtn').disabled = true;
            document.getElementById('stopBtn').disabled = false;
            document.getElementById('recordingStatus').textContent = 'Recording...';
            document.getElementById('recordingStatus').className = 'text-sm text-red-600 mb-2';

            // Start timer
            let seconds = 0;
            recordingTimer = setInterval(() => {
                seconds = Math.floor((Date.now() - startTime) / 1000);
                const minutes = Math.floor(seconds / 60);
                const remainingSeconds = seconds % 60;
                document.getElementById('timer').textContent =
                    `${minutes.toString().padStart(2, '0')}:${remainingSeconds.toString().padStart(2, '0')}`;

                // Auto-stop after 2 minutes
                if (seconds >= 120) {
                    stopRecording();
                }
            }, 1000);

            // Start waveform visualization
            startWaveformVisualization(stream);
        })
        .catch(error => {
            console.error('Error accessing microphone:', error);
            alert('Error accessing microphone. Please check permissions.');
        });
}

function stopRecording() {
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
    }

    clearInterval(recordingTimer);

    // Update UI
    document.getElementById('recordBtn').disabled = false;
    document.getElementById('stopBtn').disabled = true;
    document.getElementById('uploadBtn').disabled = false;
    document.getElementById('recordingStatus').textContent = 'Recording stopped';
    document.getElementById('recordingStatus').className = 'text-sm text-green-600 mb-2';

    // Stop waveform visualization
    stopWaveformVisualization();
}

function uploadRecording() {
    if (audioChunks.length === 0) {
        alert('No recording to upload');
        return;
    }

    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
    const formData = new FormData();
    formData.append('audio', audioBlob, 'voice_log.wav');

    // Show upload status
    document.getElementById('uploadStatus').classList.remove('hidden');

    fetch('/api/upload-voice', {
        method: 'POST',
        body: formData,
        headers: {
            'X-CSRFToken': document.querySelector('meta[name="csrf-token"]') ? document.querySelector('meta[name="csrf-token"]').getAttribute('content') : ''
        }
    })
    .then(response => response.json())
    .then(data => {
        document.getElementById('uploadStatus').classList.add('hidden');

        if (data.success) {
            location.reload(); // Refresh to show new voice log
        } else {
            alert('Upload failed: ' + data.message);
        }
    })
    .catch(error => {
        document.getElementById('uploadStatus').classList.add('hidden');
        console.error('Upload error:', error);
        alert('Upload failed. Please try again.');
    });
}

// Simple waveform visualization
let audioContext, analyser, dataArray, canvasCtx, animationId;

function startWaveformVisualization(stream) {
    audioContext = new (window.AudioContext || window.webkitAudioContext)();
    analyser = audioContext.createAnalyser();
    const source = audioContext.createMediaStreamSource(stream);
    source.connect(analyser);

    analyser.fftSize = 256;
    const bufferLength = analyser.frequencyBinCount;
    dataArray = new Uint8Array(bufferLength);

    const canvas = document.getElementById('waveform');
    canvasCtx = canvas.getContext('2d');
    canvasCtx.clearRect(0, 0, canvas.width, canvas.height);

    function draw() {
        const drawVisual = requestAnimationFrame(draw);

        analyser.getByteFrequencyData(dataArray);

        canvasCtx.fillStyle = '#f3f4f6';
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

        canvasCtx.lineWidth = 2;
        canvasCtx.strokeStyle = '#3b82f6';
        canvasCtx.beginPath();

        const sliceWidth = canvas.width * 1.0 / bufferLength;
        let x = 0;

        for (let i = 0; i < bufferLength; i++) {
            const v = dataArray[i] / 128.0;
            const y = v * canvas.height / 2;

            if (i === 0) {
                canvasCtx.moveTo(x, y);
            } else {
                canvasCtx.lineTo(x, y);
            }

            x += sliceWidth;
        }

        canvasCtx.stroke();
    }

    draw();
}

function stopWaveformVisualization() {
    if (animationId) {
        cancelAnimationFrame(animationId);
    }
    if (audioContext) {
        audioContext.close();
    }
    const canvas = document.getElementById('waveform');
    const canvasCtx = canvas.getContext('2d');
    canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
}

function deleteVoiceLog(logId) {
    if (confirm('Are you sure you want to delete this voice log? This action cannot be undone.')) {
        fetch(`/api/delete-voice-log/${logId}`, {
            method: 'DELETE',
            headers: {
                'Content-Type': 'application/json',
                'X-CSRFToken': document.querySelector('meta[name="csrf-token"]') ? document.querySelector('meta[name="csrf-token"]').getAttribute('content') : ''
            }
        })
        .then(response => response.json())
        .then(data => {
            if (data.success) {
                // Remove the log entry from the DOM
                const logElement = document.querySelector(`[data-log-id="${logId}"]`);
                if (logElement) {
                    logElement.remove();
                }

                // Show success message
                showAlert('Voice log deleted successfully!', 'success');

                // If no logs left, show empty state
                const logsContainer = document.querySelector('.space-y-4');
                if (logsContainer && logsContainer.children.length === 0) {
                    location.reload(); // Refresh to show empty state
                }
            } else {
                showAlert('Failed to delete voice log: ' + data.message, 'error');
            }
        })
        .catch(error => {
            console.error('Delete error:', error);
            showAlert('Failed to delete voice log. Please try again.', 'error');
        });
    }
}

function showAlert(message, type) {
    // Create alert element
    const alertDiv = document.createElement('div');
    alertDiv.className = `alert alert-${type} mb-4 p-4 rounded-lg text-sm ${
        type === 'success'
            ? 'bg-green-100 text-green-800 border border-green-200'
            : 'bg-red-100 text-red-800 border border-red-200'
    }`;
    alertDiv.textContent = message;

    // Insert at the top of the content area
    const container = document.querySelector('.patient-voice-logs-container .max-w-4xl');
    container.insertBefore(alertDiv, container.firstChild);

    // Remove after 5 seconds
    setTimeout(() => {
        if (alertDiv.parentNode) {
            alertDiv.remove();
        }
    }, 5000);
}

// Check for microphone permissions on page load
document.addEventListener('DOMContentLoaded', function() {
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(() => {
                console.log('Microphone access granted');
            })
            .catch(() => {
                console.log('Microphone access denied');
                document.getElementById('recordingStatus').textContent = 'Microphone access required';
                document.getElementById('recordingStatus').className = 'text-sm text-red-600 mb-2';
            });
    }
});
</script>
{% endblock %}
